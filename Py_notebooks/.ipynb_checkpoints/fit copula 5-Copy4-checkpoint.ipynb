{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from copulae1 import *\n",
    "from KDEs import *\n",
    "from toolbox import *\n",
    "import warnings\n",
    "import itertools\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = pd.read_csv('../processed_data/btc_future_crix.csv')\n",
    "data.head()\n",
    "\n",
    "ecdf_brr = ECDF(data.return_brr)\n",
    "ecdf_btc = ECDF(data.return_btc)\n",
    "\n",
    "u = ecdf_brr(data.return_brr)\n",
    "v = ecdf_btc(data.return_btc)\n",
    "\n",
    "brr = np.array(data.return_brr)\n",
    "btc = np.array(data.return_btc)\n",
    "\n",
    "kde_brr = KDE(data.return_brr, \"Gaussian\")\n",
    "kde_btc = KDE(data.return_btc, \"Gaussian\")\n",
    "\n",
    "kde_brr = KDE(data.return_brr, \"Gaussian\", kde_brr.h_brot*3)\n",
    "kde_btc = KDE(data.return_brr, \"Gaussian\", kde_btc.h_brot*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian, t_Copula, Clayton, Frank, Gumbel, Plackett, Gaussian mix Indep\n",
    "C1  = Gaussian(dict(rho=0.9),       Law_RS=kde_brr, Law_RF=kde_btc) # fix the maringals!\n",
    "C2  = t_Copula(dict(rho=0.1, nu=4), Law_RS=kde_brr, Law_RF=kde_btc, nu_lowerbound=2) \n",
    "C2c = t_Copula(dict(rho=0.1, nu=4), Law_RS=kde_brr, Law_RF=kde_btc, nu_lowerbound=4) \n",
    "C3  = Clayton(dict(theta=0.1),      Law_RS=kde_brr, Law_RF=kde_btc)\n",
    "C4  = Frank(dict(theta=0.1),        Law_RS=kde_brr, Law_RF=kde_btc)\n",
    "C5  = Gumbel(dict(theta=3),         Law_RS=kde_brr, Law_RF=kde_btc)\n",
    "C6  = Plackett(dict(theta=10),      Law_RS=kde_brr, Law_RF=kde_btc)\n",
    "C7  = Gaussian_Mix_Independent(dict(rho=.5,p=0.7),Law_RS=kde_brr, Law_RF=kde_btc)\n",
    "Copulae_names = ['Gaussian', 't_Copula', 't_Copula_Capped', 'Clayton', 'Frank', 'Gumbel', 'Plackett', 'Gauss Mix Indep']\n",
    "Copulae_arr   = [C1,C2,C2c,C3,C4,C5,C6,C7]\n",
    "Copulae = dict(zip(Copulae_names, Copulae_arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_name = \"future_brr_v5\"\n",
    "data_path = \"../processed_data/\"+data_name+\"/\"\n",
    "\n",
    "# Risk Measures\n",
    "# Variance is automatically included\n",
    "k_arr = [10,20] # Absolute risk aversion for exponential risk measure\n",
    "q_arr_ES = [0.01,0.05,0.1] # Quantile level for expected shortfall\n",
    "\n",
    "spot_name = \"log return brr\"\n",
    "future_name = \"log return future\"\n",
    "\n",
    "paras_results = []\n",
    "likelihood_results = []\n",
    "best_h_results = []\n",
    "\n",
    "calibration_method = \"MLE\" # MM or MLE\n",
    "q_arr = [0.05,0.1,0.9,0.95]\n",
    "\n",
    "ls = os.listdir(data_path+'train/')\n",
    "ls = [l for l in ls if l.endswith('.csv')]\n",
    "for file in ls:\n",
    "    # Calibration \n",
    "    train = pd.read_csv(data_path+'train/'+file)\n",
    "    spot   = train.loc[:,spot_name]\n",
    "    future = train.loc[:,future_name]\n",
    "    u = ECDF(spot)(spot)\n",
    "    v = ECDF(future)(future)\n",
    "    \n",
    "    kde_brr = KDE(spot, \"Gaussian\")\n",
    "    kde_btc = KDE(future, \"Gaussian\")\n",
    "    \n",
    "    for C_name in Copulae:\n",
    "        Copulae[C_name].Law_RS = kde_brr\n",
    "        Copulae[C_name].Law_RF = kde_btc\n",
    "    \n",
    "    paras = []\n",
    "    likelihood = []\n",
    "    best_h = []\n",
    "    for C_name in Copulae:\n",
    "        if calibration_method == \"MLE\":\n",
    "            Copulae[C_name].canonical_calibrate(u,v)\n",
    "            \n",
    "        elif calibration_method == \"MM\":\n",
    "            Copulae[C_name].mm_calibrate(u,v,q_arr)\n",
    "\n",
    "        print(C_name,'is done.\\n')\n",
    "    \n",
    "    for C_name in Copulae:\n",
    "        paras.append((C_name,Copulae[C_name].paras))\n",
    "        \n",
    "    for C_name in Copulae:\n",
    "        ln = Copulae[C_name].dependency_likelihood(u,v)\n",
    "        likelihood.append((C_name,ln))\n",
    "        \n",
    "    paras_results.append(paras)\n",
    "    likelihood_results.append(likelihood)\n",
    "    \n",
    "    # Get Best h\n",
    "    best_h = []\n",
    "    for C_name in Copulae:\n",
    "        best_h.append(optimize_h(Copulae[C_name], k_arr, q_arr_ES))\n",
    "    best_h = pd.DataFrame(best_h)\n",
    "    best_h.columns = ['Var'] + ['ERM k=%i'%k for k in k_arr] +  ['ES q=%.2f'%q for q in q_arr_ES]\n",
    "    best_h.index = Copulae_names \n",
    "    best_h_results.append(best_h)\n",
    "    \n",
    "#     # Testing\n",
    "#     test = pd.read_csv(data_path+'test/'+file)\n",
    "#     spot_test   = train.loc[:,spot_name]\n",
    "#     future_test = train.loc[:,future_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_arr = []\n",
    "date_range_arr = []\n",
    "for i, file in enumerate(ls):\n",
    "    train = pd.read_csv(data_path+'train/'+file)\n",
    "    date_range = train.Date.iloc[-1] +' to ' + train.Date.iloc[0]\n",
    "    date_range_arr.append(date_range)\n",
    "    \n",
    "    c = pd.DataFrame(paras_results[i])\n",
    "    c.index = c.iloc[:,0]\n",
    "    c = pd.DataFrame(c.iloc[:,1])\n",
    "#     c.columns = ['paras']\n",
    "    c_arr.append(c)\n",
    "    \n",
    "paras_results_pd = pd.concat(dict(zip(ls, c_arr)), axis=1)\n",
    "paras_results_pd.columns = paras_results_pd.columns.droplevel(1)\n",
    "paras_results_pd.index.name= None\n",
    "\n",
    "l_arr = []\n",
    "date_range_arr = []\n",
    "for i, file in enumerate(ls):\n",
    "    train = pd.read_csv(data_path+'train/'+file)\n",
    "    date_range = train.Date.iloc[-1] +' to ' + train.Date.iloc[0]\n",
    "    date_range_arr.append(date_range)\n",
    "    \n",
    "    c = pd.DataFrame(likelihood_results[i])\n",
    "    c.index = c.iloc[:,0]\n",
    "    c = pd.DataFrame(c.iloc[:,1])\n",
    "#     c.columns = ['likelihood']\n",
    "    l_arr.append(c)\n",
    "    \n",
    "likelihood_results_pd = pd.concat(dict(zip(ls, l_arr)), axis=1)\n",
    "likelihood_results_pd.columns = likelihood_results_pd.columns.droplevel(1)\n",
    "likelihood_results_pd.index.name= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "paras_results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_h_results_pd = pd.concat(dict(zip(ls, best_h_results)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap(h):\n",
    "    if h < 0:\n",
    "        return 0\n",
    "    elif h >1:\n",
    "        return 1\n",
    "    else:\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = best_h_results_pd.columns\n",
    "for c in columns:\n",
    "     best_h_results_pd.loc[:,c] = best_h_results_pd.loc[:,c].apply(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hedging_effectiveness(h_arr, spot, future, k_arr, q_arr):\n",
    "    results = np.ones((len(h_arr),1+len(k_arr)+len(q_arr)))\n",
    "    for i, h in enumerate(h_arr):\n",
    "        rh = spot-h*future\n",
    "        results[i,:]=1-risk_measures(k_arr, q_arr, rh)/risk_measures(k_arr, q_arr, spot)\n",
    "    return np.array([results[i,i] for i in range(len(h_arr))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range_arr = []\n",
    "for i, file in enumerate(ls):\n",
    "    train = pd.read_csv(data_path+'train/'+file)\n",
    "    date_range = train.Date.iloc[-1] +' to ' + train.Date.iloc[0]\n",
    "    date_range_arr.append(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_likelihood = likelihood_results_pd.copy()\n",
    "display_likelihood.columns = date_range_arr\n",
    "display_likelihood = display_likelihood.reindex(sorted(display_likelihood.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_paras = paras_results_pd.copy()\n",
    "display_paras.columns = date_range_arr\n",
    "display_paras = display_paras.reindex(sorted(display_paras.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_best_h = best_h_results_pd.copy()\n",
    "display_best_h.columns.set_levels(date_range_arr, level=0, inplace=True)\n",
    "display_best_h = display_best_h.reindex(sorted(display_best_h.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../results/\" + data_name)==False:\n",
    "    print(\"Create new folder for results\")\n",
    "    os.mkdir(\"../results/\" + data_name)\n",
    "    os.mkdir(\"../results/\" + data_name +\"/MLE\")\n",
    "    os.mkdir(\"../results/\" + data_name +\"/MM\")\n",
    "    \n",
    "if calibration_method == \"MLE\":\n",
    "    path = \"../results/\"+ data_name +\"/MLE/\"\n",
    "    paras_results_pd.to_json(path+\"parameters.json\")\n",
    "    likelihood_results_pd.to_json(path+\"likelihood.json\")\n",
    "    best_h_results_pd.to_json(path+\"best_h.json\")\n",
    "    \n",
    "    display_paras.to_html(path+\"paras.html\")\n",
    "    display_likelihood.to_html(path+\"likelihood.html\")\n",
    "    display_best_h.to_html(path+\"best_h.html\")\n",
    "\n",
    "    \n",
    "elif calibration_method == \"MM\":\n",
    "    path = \"../results/\"+ data_name +\"/MM/\"\n",
    "    paras_results_pd.to_json(path+\"parameters.json\")\n",
    "    likelihood_results_pd.to_json(path+\"likelihood.json\")\n",
    "    best_h_results_pd.to_json(path+\"best_h.json\")\n",
    "    \n",
    "    display_paras.to_html(path+\"paras.html\")\n",
    "    display_likelihood.to_html(path+\"likelihood.html\")\n",
    "    display_best_h.to_html(path+\"best_h.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HE_results = []\n",
    "\n",
    "for i, file in enumerate(ls):\n",
    "    test = pd.read_csv(data_path+'train/'+file)\n",
    "    spot   = test.loc[:,spot_name]\n",
    "    future = test.loc[:,future_name]\n",
    "    fn = lambda h_arr: hedging_effectiveness(h_arr, spot, future, k_arr, q_arr)\n",
    "    HE = pd.DataFrame().reindex_like(best_h_results[0])\n",
    "    HEs = best_h_results[i].apply(fn, axis=1)\n",
    "    for i in range(len(HEs)):\n",
    "        HE.iloc[i,:] = HEs[i]\n",
    "    HE_results.append(HE)\n",
    "HE_results_pd = pd.concat(dict(zip(ls, HE_results)), axis=1)\n",
    "risk_measure_names = HE_results_pd.droplevel(0,axis=1).columns.unique()\n",
    "\n",
    "fig, ax = plt.subplots(len(risk_measure_names), 1, figsize=(10,5*len(risk_measure_names)))\n",
    "for i, name in enumerate(risk_measure_names): \n",
    "    ax[i].boxplot(HE_results_pd.droplevel(0,axis=1).loc[:,name])\n",
    "    ax[i].set_xticklabels(Copulae_names)\n",
    "    ax[i].set_title(\"In Sample Hedging Effectiveness of %s\"%name)\n",
    "    \n",
    "if calibration_method == \"MLE\":\n",
    "    fig.savefig(\"../results/\"+ data_name +\"/MLE/\"+\"In Sample Hedging Effectiveness.png\", transparent=True)    \n",
    "elif calibration_method == \"MM\":\n",
    "    fig.savefig(\"../results/\"+ data_name +\"/MM/\"+\"In Sample Hedging Effectiveness.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "HE_results = []\n",
    "\n",
    "for i, file in enumerate(ls):\n",
    "    test = pd.read_csv(data_path+'test/'+file)\n",
    "    spot   = test.loc[:,spot_name]\n",
    "    future = test.loc[:,future_name]\n",
    "    fn = lambda h_arr: hedging_effectiveness(h_arr, spot, future, k_arr, q_arr)\n",
    "    HE = pd.DataFrame().reindex_like(best_h_results[0])\n",
    "    HEs = best_h_results[i].apply(fn, axis=1)\n",
    "    for i in range(len(HEs)):\n",
    "        HE.iloc[i,:] = HEs[i]\n",
    "    HE_results.append(HE)\n",
    "HE_results_pd = pd.concat(dict(zip(ls, HE_results)), axis=1)\n",
    "risk_measure_names = HE_results_pd.droplevel(0,axis=1).columns.unique()\n",
    "\n",
    "fig, ax = plt.subplots(len(risk_measure_names), 1, figsize=(10,5*len(risk_measure_names)))\n",
    "for i, name in enumerate(risk_measure_names): \n",
    "    ax[i].boxplot(HE_results_pd.droplevel(0,axis=1).loc[:,name])\n",
    "#     ax[i].set_xticks(np.linspace(1,len(Copulae_names)))\n",
    "    ax[i].set_xticklabels(Copulae_names)\n",
    "    ax[i].set_title(\"Out of Sample Hedging Effectiveness of %s\"%name)\n",
    "if calibration_method == \"MLE\":\n",
    "    fig.savefig(\"../results/\"+ data_name +\"/MLE/\"+\"Out of Sample Hedging Effectiveness.png\", transparent=True)    \n",
    "elif calibration_method == \"MM\":\n",
    "    fig.savefig(\"../results/\"+ data_name +\"/MM/\"+\"Out of Sample Hedging Effectiveness.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
